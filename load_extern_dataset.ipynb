{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_meta = 'C:/Users/Sam/Downloads/HO3D_v3/HO3D_v3/HO3D_v3/train/ABF10/meta'\n",
    "i = np.random.randint(0,len(os.listdir(path_meta)),1).item()\n",
    "os.path.join(path_meta, os.listdir(path_meta)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0,len(os.listdir(path_meta)),1).item()\n",
    "meta = np.load(os.path.join(path_meta, os.listdir(path_meta)[i]), allow_pickle=True)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = R.from_rotvec(meta['objRot'][:,0])\n",
    "m=np.linalg.inv(r.as_matrix())\n",
    "m=np.concatenate([m,np.zeros((1,3))])\n",
    "m=np.concatenate([m,np.concatenate([-meta['objTrans'],np.ones(1)])[:,None]],1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import cv2\n",
    "\n",
    "base_folder = 'C:/Users/Sam/Downloads/HO3D_v3/HO3D_v3/HO3D_v3/train/ABF10'\n",
    "path_meta = os.path.join(base_folder, 'meta')\n",
    "path_images = os.path.join(base_folder, 'images')\n",
    "\n",
    "# Read the intrinsic camera matrix from the metadata\n",
    "meta = np.load(os.path.join(path_meta, os.listdir(path_meta)[0]), allow_pickle=True)\n",
    "cam_mat = meta['camMat']\n",
    "\n",
    "# Extract the intrinsic camera parameters\n",
    "fl_x = cam_mat[0, 0]\n",
    "fl_y = cam_mat[1, 1]\n",
    "cx = cam_mat[0, 2]\n",
    "cy = cam_mat[1, 2]\n",
    "\n",
    "# Read the image dimensions\n",
    "image_files = os.listdir(path_images)\n",
    "image_path = os.path.join(path_images, image_files[0])\n",
    "image = cv2.imread(image_path)\n",
    "h, w, _ = image.shape\n",
    "\n",
    "# Calculate camera angles (assuming a pinhole camera model)\n",
    "camera_angle_x = np.arctan2(w - cx, fl_x)\n",
    "camera_angle_y = np.arctan2(h - cy, fl_y)\n",
    "\n",
    "# Create the JSON data structure\n",
    "data = {\n",
    "    \"camera_angle_x\": float(camera_angle_x),\n",
    "    \"camera_angle_y\": float(camera_angle_y),\n",
    "    \"fl_x\": float(fl_x),\n",
    "    \"fl_y\": float(fl_y),\n",
    "    \"k1\": 0.0,\n",
    "    \"k2\": 0.0,\n",
    "    \"k3\": 0.0,\n",
    "    \"k4\": 0.0,\n",
    "    \"p1\": 0.0,\n",
    "    \"p2\": 0.0,\n",
    "    \"is_fisheye\": False,\n",
    "    \"cx\": float(cx),\n",
    "    \"cy\": float(cy),\n",
    "    \"w\": float(w),\n",
    "    \"h\": float(h),\n",
    "    \"aabb_scale\": 2,\n",
    "    \"frames\": []\n",
    "}\n",
    "\n",
    "for meta_file in os.listdir(path_meta):\n",
    "    meta_path = os.path.join(path_meta, meta_file)\n",
    "    try:\n",
    "        meta = np.load(meta_path, allow_pickle=True)\n",
    "\n",
    "        # Calculate the transformation matrix\n",
    "        m = cv2.Rodrigues(meta['objRot'])[0].T\n",
    "        m = np.concatenate([m, np.zeros((1, 3))])\n",
    "        m = np.concatenate([m, np.concatenate([- np.matmul(meta['objTrans'],cv2.Rodrigues(meta['objRot'])[0]), np.ones(1)])[:, None]], 1)\n",
    "\n",
    "        # Prepare the frame entry\n",
    "        frame = {\n",
    "            \"file_path\": os.path.join('./images', meta_file.replace('.pkl', '.jpg')),\n",
    "            \"sharpness\": 150.,#float(meta['sharpness']),  # Replace with the actual sharpness value calculation\n",
    "            \"transform_matrix\": m.tolist()\n",
    "        }\n",
    "\n",
    "        # Add the frame entry to the JSON data\n",
    "        data[\"frames\"].append(frame)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {meta_file}: {str(e)}\")\n",
    "\n",
    "# Write the JSON data to a file\n",
    "json_file = os.path.join(base_folder, 'transform.json')\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "print(\"JSON file generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "base_folder = 'C:/Users/Sam/Downloads/HO3D_v3/HO3D_v3/HO3D_v3/train/ABF10'\n",
    "#base_folder = '/path/to/base/folder'\n",
    "\n",
    "# Path to the meta folder\n",
    "path_meta = os.path.join(base_folder, 'meta')\n",
    "\n",
    "# Path to the images folder\n",
    "path_images = os.path.join(base_folder, 'images')\n",
    "\n",
    "# Path to the depth folder\n",
    "path_depth = os.path.join(base_folder, 'depth')\n",
    "\n",
    "# Depth scale factor\n",
    "depth_scale = 0.00012498664727900177\n",
    "\n",
    "# Number of random images to load\n",
    "n = 2\n",
    "\n",
    "# Radius for filtering points\n",
    "radius = 0.5\n",
    "\n",
    "# List to store the point cloud data for each image\n",
    "point_clouds = []\n",
    "\n",
    "# Randomly select n images\n",
    "meta_files = np.random.choice(os.listdir(path_meta), n)\n",
    "\n",
    "\n",
    "# Create plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Process each image\n",
    "for meta_file in meta_files:\n",
    "    # Load metadata\n",
    "    meta_path = os.path.join(path_meta, meta_file)\n",
    "    image_file = os.path.splitext(meta_file)[0] + '.jpg'\n",
    "    image_path = os.path.join(path_images, image_file)\n",
    "    depth_file = os.path.splitext(meta_file)[0] + '.png'\n",
    "    depth_path = os.path.join(path_depth, depth_file)\n",
    "    \n",
    "    if not os.path.isfile(meta_path) or not os.path.isfile(image_path) or not os.path.isfile(depth_path):\n",
    "        continue\n",
    "\n",
    "    meta = np.load(meta_path, allow_pickle=True)\n",
    "\n",
    "    # Load camera matrix\n",
    "    cam_mat = meta['camMat']\n",
    "    fx = cam_mat[0, 0]\n",
    "    fy = cam_mat[1, 1]\n",
    "    cx = cam_mat[0, 2]\n",
    "    cy = cam_mat[1, 2]\n",
    "\n",
    "    # Load object rotation and translation\n",
    "    obj_rot = meta['objRot'][:, 0]\n",
    "    obj_trans = meta['objTrans']\n",
    "\n",
    "    # Calculate camera transformation matrix\n",
    "    #r = R.from_rotvec(obj_rot)\n",
    "    #m = r.as_matrix()\n",
    "    m = cv2.Rodrigues(meta['objRot'])[0].T\n",
    "    m = np.concatenate([m, np.zeros((1, 3))])\n",
    "    m = np.concatenate([m, np.concatenate([- np.matmul(meta['objTrans'],cv2.Rodrigues(meta['objRot'])[0]), np.ones(1)])[:, None]], 1)\n",
    "\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Load depth map\n",
    "    depth_img = cv2.imread(depth_path)\n",
    "    dpt = depth_img[:, :, 2] + depth_img[:, :, 1] * 256\n",
    "    dpt = dpt * depth_scale\n",
    "\n",
    "    # Get image shape\n",
    "    image_shape = image.shape[:2]\n",
    "\n",
    "    # Calculate image coordinates (u, v) and depth coordinates (x, y, z)\n",
    "    u, v = np.meshgrid(np.arange(image_shape[1]), np.arange(image_shape[0]))\n",
    "    x = (u - cx) * dpt / fx\n",
    "    y = -(v - cy) * dpt / fy\n",
    "    z = -dpt\n",
    "\n",
    "\n",
    "\n",
    "    # Create homogeneous coordinate matrix\n",
    "    coordinates = np.stack((x, y, z, np.ones_like(x)), axis=2)\n",
    "\n",
    "    # Transform coordinates to object reference frame\n",
    "    transformed_coordinates = np.matmul(m, coordinates.reshape(-1, 4).T).T\n",
    "    print(transformed_coordinates.shape)\n",
    "\n",
    "    # Extract transformed points and colors\n",
    "    transformed_points = transformed_coordinates[:, :3].T\n",
    "    colors = image.reshape(-1, 3) / 255.0\n",
    "\n",
    "    # Apply filtering based on radius\n",
    "    distances = np.linalg.norm(transformed_points, axis=0)\n",
    "    filtered_indices = np.where(distances <= radius)[0]\n",
    "    filtered_points = transformed_points[:, filtered_indices]\n",
    "    filtered_colors = colors[filtered_indices]\n",
    "\n",
    "    print(filtered_points.shape)\n",
    "\n",
    "    # Add filtered point cloud to the list\n",
    "    point_clouds.append((filtered_points, filtered_colors))\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=filtered_points[0],\n",
    "        y=filtered_points[1],\n",
    "        z=filtered_points[2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=1,\n",
    "            color=filtered_colors,\n",
    "            opacity=0.8\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "    # Add object bounding box corners to the plot\n",
    "    objCorners = meta['objCorners3DRest']\n",
    "    #objCornersTrans = np.matmul(objCorners, cv2.Rodrigues(meta['objRot'])[0].T) + meta['objTrans']\n",
    "    corners_x = objCorners[:, 0]\n",
    "    corners_y = objCorners[:, 1]\n",
    "    corners_z = objCorners[:, 2]\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(x=corners_x, y=corners_y, z=corners_z,\n",
    "                            mode='markers', marker=dict(size=5, color='red')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set layout\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis=dict(range=[-radius, radius]),\n",
    "    yaxis=dict(range=[-radius, radius]),\n",
    "    zaxis=dict(range=[-radius, radius]),\n",
    "    aspectmode='manual',\n",
    "    aspectratio=dict(x=1, y=1, z=1),\n",
    "    camera=dict(\n",
    "        eye=dict(x=0.5, y=0.5, z=0.2),\n",
    "        up=dict(x=0, y=0, z=1),\n",
    "        center=dict(x=0, y=0, z=0)\n",
    "    )\n",
    "))\n",
    "\n",
    "# Show the animation\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "base_folder = 'C:/Users/Sam/Downloads/HO3D_v3/HO3D_v3/HO3D_v3/train/ABF10'\n",
    "#base_folder = '/path/to/base/folder'\n",
    "\n",
    "# Path to the meta folder\n",
    "path_meta = os.path.join(base_folder, 'meta')\n",
    "\n",
    "# Path to the images folder\n",
    "path_images = os.path.join(base_folder, 'images')\n",
    "\n",
    "# Path to the depth folder\n",
    "path_depth = os.path.join(base_folder, 'depth')\n",
    "\n",
    "# Depth scale factor\n",
    "depth_scale = 0.00012498664727900177\n",
    "\n",
    "# Number of random images to load\n",
    "n = 2\n",
    "\n",
    "# Radius for filtering points\n",
    "radius = 2.\n",
    "\n",
    "# List to store the point cloud data for each image\n",
    "point_clouds = []\n",
    "\n",
    "# Randomly select n images\n",
    "meta_file = np.random.choice(os.listdir(path_meta), n)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load metadata\n",
    "meta_path = os.path.join(path_meta, meta_file)\n",
    "image_file = os.path.splitext(meta_file)[0] + '.jpg'\n",
    "image_path = os.path.join(path_images, image_file)\n",
    "depth_file = os.path.splitext(meta_file)[0] + '.png'\n",
    "depth_path = os.path.join(path_depth, depth_file)\n",
    "\n",
    "meta = np.load(meta_path, allow_pickle=True)\n",
    "\n",
    "# Load camera matrix\n",
    "cam_mat = meta['camMat']\n",
    "fx = cam_mat[0, 0]\n",
    "fy = cam_mat[1, 1]\n",
    "cx = cam_mat[0, 2]\n",
    "cy = cam_mat[1, 2]\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Load depth map\n",
    "depth_img = cv2.imread(depth_path)\n",
    "dpt = depth_img[:, :, 2] + depth_img[:, :, 1] * 256\n",
    "dpt = dpt * depth_scale\n",
    "\n",
    "# Get image shape\n",
    "image_shape = image.shape[:2]\n",
    "\n",
    "# Calculate image coordinates (u, v) and depth coordinates (x, y, z)\n",
    "u, v = np.meshgrid(np.arange(image_shape[1]), np.arange(image_shape[0]))\n",
    "x = (u - cx) * dpt / fx\n",
    "y = -(v - cy) * dpt / fy\n",
    "z = -dpt\n",
    "\n",
    "# Create homogeneous coordinate matrix\n",
    "coordinates = np.stack((x, y, z, np.ones_like(x)), axis=2)\n",
    "\n",
    "m = cv2.Rodrigues(meta['objRot'])[0].T\n",
    "m = np.concatenate([m, np.zeros((1, 3))])\n",
    "m = np.concatenate([m, np.concatenate([- np.matmul(meta['objTrans'],cv2.Rodrigues(meta['objRot'])[0]), np.ones(1)])[:, None]], 1)\n",
    "\n",
    "# Transform coordinates to object reference frame\n",
    "coordinates = np.matmul(m, coordinates.reshape(-1, 4).T).T\n",
    "\n",
    "# # Create homogeneous coordinate matrix\n",
    "# coordinates = np.stack((x, y, z), axis=2)\n",
    "# #coordinates = coordinates - meta['objTrans']\n",
    "# coordinates = np.matmul(coordinates,cv2.Rodrigues(meta['objRot'])[0]) - np.matmul(meta['objTrans'],cv2.Rodrigues(meta['objRot'])[0])\n",
    "\n",
    "print(coordinates.shape)\n",
    "x = coordinates[...,0]\n",
    "y = coordinates[...,1]\n",
    "z = coordinates[...,2]\n",
    "\n",
    "# Create 3D scatter plot for point cloud\n",
    "fig = go.Figure(data=go.Scatter3d(x=x.flatten(), y=y.flatten(), z=z.flatten(),\n",
    "                                 mode='markers', marker=dict(size=1)))\n",
    "\n",
    "# Add object bounding box corners to the plot\n",
    "objCorners = meta['objCorners3DRest']\n",
    "objCornersTrans = np.matmul(objCorners, cv2.Rodrigues(meta['objRot'])[0].T) + meta['objTrans']\n",
    "corners_x = objCorners[:, 0]\n",
    "corners_y = objCorners[:, 1]\n",
    "corners_z = objCorners[:, 2]\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=corners_x, y=corners_y, z=corners_z,\n",
    "                           mode='markers', marker=dict(size=5, color='red')))\n",
    "\n",
    "# Update plot layout\n",
    "# Set layout\n",
    "radius=0.5\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis=dict(range=[-radius, radius]),\n",
    "    yaxis=dict(range=[-radius, radius]),\n",
    "    zaxis=dict(range=[-radius, radius]),\n",
    "    aspectmode='manual',\n",
    "    aspectratio=dict(x=1, y=1, z=1),\n",
    "    camera=dict(\n",
    "        eye=dict(x=-0.5, y=-0.5, z=0.2),\n",
    "        up=dict(x=0, y=0, z=1),\n",
    "        center=dict(x=0, y=0, z=0)\n",
    "    )\n",
    "))\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "base_folder = 'C:/Users/Sam/Downloads/HO3D_v3/HO3D_v3/HO3D_v3/train/ABF10'\n",
    "#base_folder = '/path/to/base/folder'\n",
    "\n",
    "# Path to the meta folder\n",
    "path_meta = os.path.join(base_folder, 'meta')\n",
    "\n",
    "# Path to the images folder\n",
    "path_images = os.path.join(base_folder, 'images')\n",
    "\n",
    "# Path to the depth folder\n",
    "path_depth = os.path.join(base_folder, 'depth')\n",
    "\n",
    "# Depth scale factor\n",
    "depth_scale = 0.00012498664727900177\n",
    "\n",
    "# Number of random images to load\n",
    "n = 2\n",
    "\n",
    "# Radius for filtering points\n",
    "radius = 2.\n",
    "\n",
    "# List to store the point cloud data for each image\n",
    "point_clouds = []\n",
    "\n",
    "# Randomly select n images\n",
    "meta_file = np.random.choice(os.listdir(path_meta), n)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "meta_path = os.path.join(path_meta, meta_file)\n",
    "image_file = os.path.splitext(meta_file)[0] + '.jpg'\n",
    "image_path = os.path.join(path_images, image_file)\n",
    "depth_file = os.path.splitext(meta_file)[0] + '.png'\n",
    "depth_path = os.path.join(path_depth, depth_file)\n",
    "\n",
    "meta = np.load(meta_path, allow_pickle=True)\n",
    "\n",
    "m = cv2.Rodrigues(meta['objRot'])[0].T\n",
    "m = np.concatenate([m, np.zeros((1, 3))])\n",
    "m = np.concatenate([m, np.concatenate([- np.matmul(meta['objTrans'],cv2.Rodrigues(meta['objRot'])[0]), np.ones(1)])[:, None]], 1)\n",
    "\n",
    "cam_mat = meta['camMat']\n",
    "fx = cam_mat[0, 0]\n",
    "fy = cam_mat[1, 1]\n",
    "cx = cam_mat[0, 2]\n",
    "cy = cam_mat[1, 2]\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Get image shape\n",
    "image_shape = image.shape[:2]\n",
    "\n",
    "# Load depth map\n",
    "depth_img = cv2.imread(depth_path)\n",
    "dpt = depth_img[:, :, 2] + depth_img[:, :, 1] * 256\n",
    "dpt = dpt * depth_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extensions.cameras import Cameras\n",
    "import torch\n",
    "\n",
    "cams = Cameras( fx, fy, cx, cy, image_shape[1], image_shape[0], torch.tensor(m[None], dtype=torch.float), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, u = torch.meshgrid(torch.arange(image_shape[0]), torch.arange(image_shape[1]))\n",
    "u=u.flatten()\n",
    "v=v.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rays = cams.get_rays(torch.zeros_like(u).long(),u.float(),v.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = rays.origins + rays.dirs*dpt.flatten()[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scatter3d(x=pts[:,0], y=pts[:,1], z=pts[:,2],\n",
    "                                 mode='markers', marker=dict(size=1, color=image.reshape(-1,3))))\n",
    "\n",
    "# Add object bounding box corners to the plot\n",
    "objCorners = meta['objCorners3DRest']\n",
    "objCornersTrans = np.matmul(objCorners, cv2.Rodrigues(meta['objRot'])[0].T) + meta['objTrans']\n",
    "corners_x = objCorners[:, 0]\n",
    "corners_y = objCorners[:, 1]\n",
    "corners_z = objCorners[:, 2]\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=corners_x, y=corners_y, z=corners_z,\n",
    "                           mode='markers', marker=dict(size=5, color='red')))\n",
    "\n",
    "# Update plot layout\n",
    "# Set layout\n",
    "radius=0.5\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis=dict(range=[-radius, radius]),\n",
    "    yaxis=dict(range=[-radius, radius]),\n",
    "    zaxis=dict(range=[-radius, radius]),\n",
    "    aspectmode='manual',\n",
    "    aspectratio=dict(x=1, y=1, z=1),\n",
    "    camera=dict(\n",
    "        eye=dict(x=-0.5, y=-0.5, z=0.2),\n",
    "        up=dict(x=0, y=0, z=1),\n",
    "        center=dict(x=0, y=0, z=0)\n",
    "    )\n",
    "))\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cams.poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wisp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
